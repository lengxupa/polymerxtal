{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we can run this from python2 or python3.\n",
    "# But you should be using python3!!!\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit\n",
    "\n",
    "Tools run on the hubs are limited because they run in a container on an execution host.  Many simulations require large amounts or memory and/or CPU time.  They require access to external HPC or grid resources.  \n",
    "\n",
    "**submit** takes a user command and executes it remotely. The objective is to allow the user to issue a command in the same manner as a locally executed command. Multiple submission mechanisms are available for run dissemination. A set of steps are executed for each run submission:\n",
    "\n",
    "* Destination site is selected\n",
    "* A wrapper script is generated for remote execution.\n",
    "\n",
    "* If needed a batch system description file is generated.\n",
    "* Input files for a run are gathered and transferred to the remote site. Transferred files include the wrapper and batch description scripts.\n",
    "* The wrapper script is executed remotely.\n",
    "* Progress of the remote run is monitored until completion.\n",
    "* Output files from the run are returned to the dissemination point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "> submit --help\n",
    "Usage: submit [options]\n",
    "\n",
    "Options:\n",
    "  -h, --help            Report command usage. Optionally request listing of\n",
    "                        managers, tools, venues, or examples.\n",
    "  -l, --local           Execute command locally\n",
    "  --status              Report status for runs executing remotely.\n",
    "  -k, --kill            Kill runs executing remotely.\n",
    "  --venueStatus         Report venue status.\n",
    "  -v, --venue           Remote job destination\n",
    "  -i, --inputfile       Input file\n",
    "  -p, --parameters      Parameter sweep variables. See examples.\n",
    "  -d, --data            Parametric variable data - csv format\n",
    "  -s SEPARATOR, --separator=SEPARATOR\n",
    "                        Parameter sweep variable list separator\n",
    "  -n NCPUS, --nCpus=NCPUS\n",
    "                        Number of processors for MPI execution\n",
    "  -N PPN, --ppn=PPN     Number of processors/node for MPI execution\n",
    "  -w WALLTIME, --wallTime=WALLTIME\n",
    "                        Estimated walltime hh:mm:ss or minutes\n",
    "  -e, --env             Variable=value\n",
    "  --runName=RUNNAME     Name used for directories and files created during the\n",
    "                        run. Restricted to alphanumeric characters\n",
    "  -m, --manager         Multiprocessor job manager\n",
    "  -r NREDUNDANT, --redundancy=NREDUNDANT\n",
    "                        Number of indentical simulations to execute in\n",
    "                        parallel\n",
    "  -M, --metrics         Report resource usage on exit\n",
    "  --detach              Detach client after launching run\n",
    "  --attach=ATTACHID     Attach to previously detached started server\n",
    "  -W, --wait            Wait for reduced job load before submission\n",
    "  -Q, --quota           Enforce local user quota on remote execution host\n",
    "  -q, --noquota         Do not enforce local user quota on remote execution\n",
    "                        host\n",
    "  --tailStdout          Periodically report tail of stdout file.\n",
    "  --tailStderr          Periodically report tail of stderr file.\n",
    "  --tail                Periodically report tail of application file.\n",
    "  --progress            Show progress method. Choices are auto, curses,\n",
    "                        submit, text, pegasus, or silent.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning by Doing\n",
    "\n",
    "This notebook will demonstrate how to use submit.  First it will show command line usage that will not require Python.  Then it will show some how to use a python convenience function to run submit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Venues\n",
    "\n",
    "Submit can submit to different hosts or clusters. You can get a list for your hub by asking submit:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Currently available VENUES are:\r\n",
      "   OSGFactory\r\n",
      "   RedCloud\r\n",
      "   compute@comet_nanobio\r\n",
      "   conte\r\n",
      "   datalimited@rice\r\n",
      "   ncn-hub@conte\r\n",
      "   ncn-hub@rice\r\n",
      "   ncn-hub_L@conte\r\n",
      "   ncn-hub_L@rice\r\n",
      "   ncn-hub_M@conte\r\n",
      "   ncn-hub_M@rice\r\n",
      "   ncn-hub_S@conte\r\n",
      "   ncn-hub_S@rice\r\n",
      "   ncn-hub_XL@conte\r\n",
      "   ncn-hub_XL@rice\r\n",
      "   ncn@conte\r\n",
      "   ncn@rice\r\n",
      "   ncn_L@conte\r\n",
      "   ncn_L@rice\r\n",
      "   ncn_M@conte\r\n",
      "   ncn_M@rice\r\n",
      "   ncn_S@conte\r\n",
      "   ncn_S@rice\r\n",
      "   ncn_XL@conte\r\n",
      "   ncn_XL@rice\r\n",
      "   partner@halsteadgpu\r\n",
      "   punch\r\n",
      "   rcac-ncn\r\n",
      "   rcac-ncn-hub\r\n",
      "   rcac-standby\r\n",
      "   rcac_L\r\n",
      "   rcac_M\r\n",
      "   rcac_S\r\n",
      "   rcac_XL\r\n",
      "   rice\r\n",
      "   shared@comet_nanobio\r\n",
      "   standby@conte\r\n",
      "   standby@rice\r\n",
      "   standby_L@conte\r\n",
      "   standby_L@rice\r\n",
      "   standby_M@conte\r\n",
      "   standby_M@rice\r\n",
      "   standby_S@conte\r\n",
      "   standby_S@rice\r\n",
      "   standby_XL@conte\r\n",
      "   standby_XL@rice\r\n",
      "   submithost\r\n"
     ]
    }
   ],
   "source": [
    "!submit --help venues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "How do we know what the default venue is?\n",
    "How should we choose the venue to use?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What commands can I submit?\n",
    "\n",
    "#### Submitting locally with --local\n",
    "\n",
    "Any executable can be used when submitting locally.  Local submit runs in the current\n",
    "execution host in the current container, so there are few reasons to use it.  However, it\n",
    "does run quickly, so it is useful for quick tests such as the ones we run in this notebook.\n",
    "\n",
    "#### Submitting to the grid\n",
    "\n",
    "Only executables staged in /apps\n",
    "can be submitted to the grid.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\r\n"
     ]
    }
   ],
   "source": [
    "!submit --local echo hi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting with Parameters\n",
    "\n",
    "Parameter examples:\n",
    "\n",
    "submit -p @@cap=10pf,100pf,1uf sim.exe @:indeck\n",
    "\n",
    "    Submit 3 jobs. The @:indeck means \"use the file indeck as a template\n",
    "    file.\" Substitute the values 10pf, 100pf, and 1uf in place of @@cap within the\n",
    "    file. Send off one job for each of the values and bring back the results.\n",
    "\n",
    "submit -p @@vth=0:0.2:5 -p @@cap=10pf,100pf,1uf sim.exe @:indeck\n",
    "\n",
    "    Submit 78 jobs. The parameter @@vth goes from 0 to 5 in steps of 0.2,\n",
    "    so there are 26 values for @@vth. For each of those values, the parameter\n",
    "    @@cap changes from 10pf to 100pf to 1uf. 26 x 3 = 78 jobs total. Again\n",
    "    @:indeck is treated as a template, and the values are substituted in place of\n",
    "    @@vth and @@cap in that file.\n",
    "\n",
    "submit -p params sim.exe @:indeck\n",
    "\n",
    "    In this case, parameter definitions are taken from the file named\n",
    "    params instead of the command line. The file might have the following\n",
    "    contents:\n",
    "\n",
    "        # paramters for my job submission\n",
    "        parameter @@vth=0:0.2:5\n",
    "        parameter @@cap = 10pf,100pf,1uf\n",
    "\n",
    "submit -p \"params;@@num=1-10;@@color=blue\" job.sh @:job.data\n",
    "\n",
    "    For someone who loves syntax and complexity... The semicolon separates\n",
    "    the parameters value into three parts. The first says to load parameters from\n",
    "    a file params. The next part says add an additional parameter @@num that goes\n",
    "    from 1 to 10. The last part says add an additional parameter @@color with a\n",
    "    single value blue. The parameters @@num and @@color cannot override anything\n",
    "    defined within params; they must be new parameter names.\n",
    "\n",
    "submit -d input.csv sim.exe @:indeck\n",
    "\n",
    "    Takes parameters from the data file input.csv, which must be in comma-\n",
    "    separated value format. The first line of this file may contain a series of\n",
    "    @@param names for each of the columns. Whitespace is significant for all\n",
    "    values entered in the csv file. If it doesn't, then the columns are assumed to\n",
    "    be called @@1, @@2, @@3, etc. Each of the remaining lines represents a set of\n",
    "    parameter values for one job; if there are 100 such lines, there will be 100\n",
    "    jobs. For example, the file input.csv might look like this:\n",
    "\n",
    "        @@vth,@@cap\n",
    "        1.1,1pf\n",
    "        2.2,1pf\n",
    "        1.1,10pf\n",
    "        2.2,10pf\n",
    "\n",
    "    Parameters are substituted as before into template files such as\n",
    "    @:indeck.\n",
    "\n",
    "submit -d input.csv -p \"@@doping=1e15-1e17 in 30 log\" sim.exe @:infile\n",
    "\n",
    "    Takes parameters from the data file input.csv, but also adds another\n",
    "    parameter @@doping which goes from 1e15 to 1e17 in 30 points on a log scale.\n",
    "    For each of these points, all values in the data file will be executed. If the\n",
    "    data file specifies 50 jobs, then this command would run 30 x 50 = 1500 jobs.\n",
    "\n",
    "submit -d input.csv -i @:extra/data.txt sim.exe @:indeck\n",
    "\n",
    "    In addition to the template indeck file, send along another file\n",
    "    extra/data.txt with each job, and treat it as a template too.\n",
    "\n",
    "submit -s / -p @@address=23 Main St.,Hometown,Indiana/42 Broadway,Hometown,Indiana -s , -p @@color=red,green,blue job.sh @:job.data\n",
    "\n",
    "    Change the separator to slash when defining the addresses, then change\n",
    "    back to comma for the @@color parameter and any remaining arguments. We\n",
    "    shouldn't have to change the separator often, but it might come in handy if\n",
    "    the value strings themselves have commas.\n",
    "\n",
    "submit -p @@num=1:1000 sim.exe input@@num\n",
    "\n",
    "    Submit jobs 1,2,3,...,1000. Parameter names such as @@num are\n",
    "    recognized not only in template files, but also for arguments on the command\n",
    "    line. In this case, the numbers 1,2,3,...,1000 are substituted into the file\n",
    "    name, so the various jobs take their input from \"input1\", \"input2\", ...,\n",
    "    \"input1000\".\n",
    "\n",
    "submit -p @@file=glob:indeck* sim.exe @@file\n",
    "\n",
    "    Look for files matching indeck* and use the list of names as the\n",
    "    parameter @@file. Those values could be substituted into other template files,\n",
    "    or used on the command line as in this example. Suppose the directory contains\n",
    "    files indeck1, indeck10, and indeck2.  The glob option will order the files in\n",
    "    a natural order: indeck1, indeck2, indeck10.  This example would launch three\n",
    "    jobs using each of those files as input for the job.\n",
    "\n",
    "submit -p @@file=globnat:indeck* sim.exe @@file\n",
    "\n",
    "    This option has been deprecated.  The functionality is now available with the glob option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the echo program with a list of different input parameters.  To see progress, we need to use \"text\" or \"submit\".  Other options won't work well with Jupyter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need this because this example is running in a read-only directory\n",
    "import os\n",
    "try:\n",
    "    os.mkdir('/tmp/submit')\n",
    "except:\n",
    "    pass\n",
    "os.chdir('/tmp/submit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulations complete. Results are stored in directory /tmp/submit/06614631\r\n"
     ]
    }
   ],
   "source": [
    "!submit --local --progress text -p @@name=hub1,hub2,hub3 echo @@name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the outputs were written to subdirectories in a directory that was created for us.\n",
    "If we want to access those results more conveniently, it would be best to tell submit what name to use for the directory.\n",
    "We can do this by using the **--runName** parameter.\n",
    "<div class=\"alert alert-info\">\n",
    "If the directory exists, submit will complain and exit immediately.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=SUBMIT-PROGRESS=> aborted=0 finished=0 failed=0 executing=0 waiting=0 setting_up=0 setup=3 %done=0.00 timestamp=1525204621.7\n",
      "=SUBMIT-PROGRESS=> aborted=0 finished=0 failed=0 executing=1 waiting=0 setting_up=0 setup=2 %done=0.00 timestamp=1525204626.0\n",
      "=SUBMIT-PROGRESS=> aborted=0 finished=1 failed=0 executing=0 waiting=0 setting_up=0 setup=2 %done=33.33 timestamp=1525204626.0\n",
      "=SUBMIT-PROGRESS=> aborted=0 finished=1 failed=0 executing=1 waiting=0 setting_up=0 setup=1 %done=33.33 timestamp=1525204626.2\n",
      "=SUBMIT-PROGRESS=> aborted=0 finished=2 failed=0 executing=0 waiting=0 setting_up=0 setup=1 %done=66.67 timestamp=1525204626.2\n",
      "=SUBMIT-PROGRESS=> aborted=0 finished=2 failed=0 executing=1 waiting=0 setting_up=0 setup=0 %done=66.67 timestamp=1525204626.4\n",
      "=SUBMIT-PROGRESS=> aborted=0 finished=3 failed=0 executing=0 waiting=0 setting_up=0 setup=0 %done=100.00 timestamp=1525204626.4\n"
     ]
    }
   ],
   "source": [
    "!rm -rf echotest\n",
    "!submit --local --runName=echotest --progress submit -s, -p @@name=hub1,hub2,hub3 echo @@name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once submit finishes, we can see the standard output for each job in the \"echotext\" subdirectory.  Standard output  will be in echotest_{jobnum}.stdout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echotest:\r\n",
      "total 20\r\n",
      "drwxr-x--- 2 mmh public 4096 May  1 15:57 01\r\n",
      "drwxr-x--- 2 mmh public 4096 May  1 15:57 02\r\n",
      "drwxr-x--- 2 mmh public 4096 May  1 15:57 03\r\n",
      "drwxr-x--- 3 mmh public 4096 May  1 15:57 mmh\r\n",
      "-rw-r----- 1 mmh public  197 May  1 15:57 parameterCombinations.csv\r\n",
      "\r\n",
      "echotest/01:\r\n",
      "total 4\r\n",
      "-rw-rw-r-- 1 mmh public 5 May  1 15:57 echotest_01.stdout\r\n",
      "\r\n",
      "echotest/02:\r\n",
      "total 4\r\n",
      "-rw-rw-r-- 1 mmh public 5 May  1 15:57 echotest_02.stdout\r\n",
      "\r\n",
      "echotest/03:\r\n",
      "total 4\r\n",
      "-rw-rw-r-- 1 mmh public 5 May  1 15:57 echotest_03.stdout\r\n",
      "\r\n",
      "echotest/mmh:\r\n",
      "total 4\r\n",
      "drwxr-x--- 3 mmh public 4096 May  1 15:57 pegasus\r\n",
      "\r\n",
      "echotest/mmh/pegasus:\r\n",
      "total 4\r\n",
      "drwxr-x--- 2 mmh public 4096 May  1 15:57 06614632\r\n",
      "\r\n",
      "echotest/mmh/pegasus/06614632:\r\n",
      "total 0\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lR echotest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 01: hub1\n",
      "\n",
      "Run 02: hub2\n",
      "\n",
      "Run 03: hub3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,4):\n",
    "    with open(\"echotest/%02d/echotest_%02d.stdout\" % (i, i), 'r') as f:\n",
    "        print(\"Run %02d: %s\" % (i, f.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# command: echo @@name\r",
      "\r\n",
      "# started: Tue May  1 15:57:01 EDT 2018\r",
      "\r\n",
      "# finished: Tue May  1 15:57:06 EDT 2018\r",
      "\r\n",
      "# completed: 3/3 jobs\r",
      "\r\n",
      "Id,Status,name\r",
      "\r\n",
      "1,finished,hub1\r",
      "\r\n",
      "2,finished,hub2\r",
      "\r\n",
      "3,finished,hub3\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat echotest/parameterCombinations.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using runCommand\n",
    "\n",
    "Using the exclamation point(!) to run shell commands from Jupyter is fine for many cases.  But often you want to call submit from a python function or check the return value.  hublib provides some very flexible python functions to do this  https://hubzero.github.io/hublib/cmd.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=SUBMIT-PROGRESS=> aborted=0 finished=0 failed=0 executing=0 waiting=5 setting_up=0 setup=0 %done=0.00 timestamp=1525204693.1\n",
      "=SUBMIT-PROGRESS=> aborted=0 finished=5 failed=0 executing=0 waiting=0 setting_up=0 setup=0 %done=100.00 timestamp=1525204791.0\n",
      "Simulations complete. Results are stored in directory /home/nanohub/mmh/data/sessions/1301182/run_NyUMtd/runtest\n"
     ]
    }
   ],
   "source": [
    "from hublib.cmd import runCommand\n",
    "!rm -rf runtest\n",
    "res, stdout, stderr = runCommand(\"submit --runName=runtest --progress submit -p @@Vin=1,2,3,4,5 /apps/pegtut/current/examples/capacitor_voltage/sim1.py  --Vin @@Vin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return code for normal completion is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the last example, we used a test program installed on nanohub so we didn't have to execute locally.  The program, \"sim1.py\" takes a single argument and outputs values to a file, \"out.log\".  It does not write to stdout.  You can see all the output in the subdirectories under \"runtest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtest:\r\n",
      "total 48\r\n",
      "drwxr-x--- 2 mmh public 4096 May  1 15:59 01\r\n",
      "drwxr-x--- 2 mmh public 4096 May  1 15:59 02\r\n",
      "drwxr-x--- 2 mmh public 4096 May  1 15:59 03\r\n",
      "drwxr-x--- 2 mmh public 4096 May  1 15:59 04\r\n",
      "drwxr-x--- 2 mmh public 4096 May  1 15:59 05\r\n",
      "-rw-r----- 1 mmh public  271 May  1 15:59 parameterCombinations.csv\r\n",
      "-rw-r----- 1 mmh public 1104 May  1 15:59 pegasus.analysis\r\n",
      "-rw-r----- 1 mmh public 2214 May  1 15:59 pegasusjobstats.csv\r\n",
      "-rw-r----- 1 mmh public 2504 May  1 15:59 pegasusjobstats.txt\r\n",
      "-rw-r----- 1 mmh public  148 May  1 15:59 pegasusstatus.txt\r\n",
      "-rw-r----- 1 mmh public 1953 May  1 15:59 pegasussummary-time.csv\r\n",
      "-rw-r----- 1 mmh public 1260 May  1 15:59 pegasussummary.csv\r\n",
      "\r\n",
      "runtest/01:\r\n",
      "total 0\r\n",
      "\r\n",
      "runtest/02:\r\n",
      "total 0\r\n",
      "\r\n",
      "runtest/03:\r\n",
      "total 0\r\n",
      "\r\n",
      "runtest/04:\r\n",
      "total 0\r\n",
      "\r\n",
      "runtest/05:\r\n",
      "total 0\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lR runtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SubmitCommand class\n",
    "\n",
    "Furthur Python integration is achieved by using the hubzero.submit.SubmitCommand class.  Methods are provided for specifying any and all **submit** arguments.  For each **submit** command argument there are typically two method types - set and reset. The standard python **help** builtin can be used to show methods and associated arguments.  The code shown here can also be used Rappture Python wrapper scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on SubmitCommand in module hubzero.submit.SubmitCommand object:\n",
      "\n",
      "class SubmitCommand(builtins.object)\n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, configurationDirectory='/etc/submit', hubLogPath='/tmp/submit/.submit.log')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  addParameters(self, parameters, separator=None)\n",
      " |      Supply additional set of parameters for submit run.\n",
      " |      parameters can be specified as a single string or\n",
      " |      of list of strings.\n",
      " |  \n",
      " |  loadSubmitCommand(self, submitCommandJSONFile)\n",
      " |      Load JSON file containing submit command settings.\n",
      " |  \n",
      " |  resetAttachId(self)\n",
      " |      Do not reattach to a previously detached submit run.\n",
      " |  \n",
      " |  resetCommand(self)\n",
      " |      Remove previous command and command argument settings.\n",
      " |  \n",
      " |  resetCommandArguments(self)\n",
      " |      Remove previous command argument settings.\n",
      " |  \n",
      " |  resetDataFile(self)\n",
      " |      Remove parameter datafile for submit run.\n",
      " |  \n",
      " |  resetDebug(self)\n",
      " |      Turn submit debug reporting off.\n",
      " |  \n",
      " |  resetDefaultSeparator(self)\n",
      " |      Set the default parameter separator to the system default.\n",
      " |  \n",
      " |  resetDefaultTailNlines(self)\n",
      " |      Set the default number of lines to report when\n",
      " |      tailing output files to the system default.\n",
      " |  \n",
      " |  resetDetach(self)\n",
      " |      Disable detachment from submit run.\n",
      " |  \n",
      " |  resetEnvironmentVariables(self)\n",
      " |      Remove all environment variables set for submit run.\n",
      " |  \n",
      " |  resetHelp(self, detail=None)\n",
      " |      Disable requests for general help or a variety of more specific help.\n",
      " |      See setHelp() for detail values.\n",
      " |  \n",
      " |  resetInputFiles(self)\n",
      " |      Remove inputfiles from submit run.\n",
      " |  \n",
      " |  resetKillJobs(self)\n",
      " |      Disable killing of previously submitted runs.\n",
      " |  \n",
      " |  resetLocal(self)\n",
      " |      Turn submit local execution off.\n",
      " |  \n",
      " |  resetManager(self)\n",
      " |      Set manager for submit run to the default manager.\n",
      " |  \n",
      " |  resetNcores(self)\n",
      " |      Set number of cores requested for submit run to the default value.\n",
      " |  \n",
      " |  resetPPN(self)\n",
      " |      Set number of cores per node requested for submit run to the default value.\n",
      " |  \n",
      " |  resetParameters(self)\n",
      " |      Remove parameters from submit run.\n",
      " |  \n",
      " |  resetProgress(self)\n",
      " |      Specify progress reporting to the default style.\n",
      " |  \n",
      " |  resetQueryJobs(self)\n",
      " |      Disable query for the status of previously submitted runs.\n",
      " |  \n",
      " |  resetQuota(self)\n",
      " |      Enable quota limit for submit run.\n",
      " |  \n",
      " |  resetRedundancy(self)\n",
      " |      Set redundancy factor for submit run to the default value.\n",
      " |  \n",
      " |  resetReportMetrics(self)\n",
      " |      Turn submit resource metrics reporting off.\n",
      " |  \n",
      " |  resetRunName(self)\n",
      " |      Set submit run name to default name.\n",
      " |  \n",
      " |  resetStdin(self)\n",
      " |      Remove previous stdin settings.\n",
      " |  \n",
      " |  resetSubmitCommand(self)\n",
      " |      Reset submit command settings to default values.\n",
      " |  \n",
      " |  resetTailFiles(self)\n",
      " |      Disable real time reporting of files other than\n",
      " |      standard output and standard error.\n",
      " |  \n",
      " |  resetTailStderr(self)\n",
      " |      Disable real time reporting of standard error file.\n",
      " |  \n",
      " |  resetTailStdout(self)\n",
      " |      Disable real time reporting of standard output file.\n",
      " |  \n",
      " |  resetVenue(self)\n",
      " |      Remove venue setting from submit command.\n",
      " |  \n",
      " |  resetVenueStatus(self)\n",
      " |      Disable request of submit venue status.\n",
      " |  \n",
      " |  resetVersion(self, detail=None)\n",
      " |      Disable requests for version information.\n",
      " |      See setVersion() for detail values.\n",
      " |  \n",
      " |  resetWait(self)\n",
      " |      Do not wait for period of reduced run submission rate to submit run.\n",
      " |      If your measured rate of job submission is to high your request for\n",
      " |      a new submit run will be denied.\n",
      " |  \n",
      " |  resetWallTime(self)\n",
      " |      Set wall time requested for submit run to the default value.\n",
      " |  \n",
      " |  saveSubmitCommand(self, submitCommandJSONFile=None)\n",
      " |      Save JSON file containing submit command settings.\n",
      " |  \n",
      " |  setAttachId(self, attachId)\n",
      " |      Reattach to a previously detached submit run.\n",
      " |  \n",
      " |  setCommand(self, command)\n",
      " |      Specify command to be run on remote resource.\n",
      " |      command can be given as a single string or a list\n",
      " |      of strings.  A single string will be split to form\n",
      " |      a list.  The first list element is taken to be the\n",
      " |      command and additional elements are taken to be\n",
      " |      command arguments.\n",
      " |  \n",
      " |  setCommandArguments(self, commandArguments)\n",
      " |      Specify command arguments to be used on remote resource.\n",
      " |      commandArguments can be given as a single string or a list\n",
      " |      of strings.  A single string will be split to form\n",
      " |      a list.\n",
      " |  \n",
      " |  setDataFile(self, dataFile)\n",
      " |      Supply parameter datafile for submit run.\n",
      " |      dataFile is a single filename.\n",
      " |  \n",
      " |  setDebug(self, debug=True)\n",
      " |      Turn submit debug reporting on or off.\n",
      " |  \n",
      " |  setDefaultSeparator(self, separatorDefault)\n",
      " |      Set the default parameter separator.\n",
      " |  \n",
      " |  setDefaultTailNlines(self, tailNlinesDefault)\n",
      " |      Set the default number of lines to report when\n",
      " |      tailing output files.\n",
      " |  \n",
      " |  setDetach(self, detach=True)\n",
      " |      Enable or disable detachment from submit run.\n",
      " |      If a job is detached you can continue with other\n",
      " |      operations and not wait for the submit to complete.\n",
      " |      Job status will need to be monitored to determine\n",
      " |      when completion occurs.  A detached can be reattached\n",
      " |      at a later time.\n",
      " |  \n",
      " |  setEnvironmentVariables(self, environmentVariables)\n",
      " |      Provide a set of environment variables to be set\n",
      " |      for submit run.  environmentVariables should be a\n",
      " |      dictionary with keys being the environment variable\n",
      " |      names.\n",
      " |  \n",
      " |  setHelp(self, detail=None)\n",
      " |      Request general help or a variety of more specific help.\n",
      " |      detail       submit arguments\n",
      " |      None         --help\n",
      " |      managers     --help managers\n",
      " |      tools        --help tools\n",
      " |      venues       --help venues\n",
      " |      examples     --help examples\n",
      " |  \n",
      " |  setInputFiles(self, inputFiles)\n",
      " |      Supply set of input files for submit run.\n",
      " |      inputFiles can be specified as a single filename or\n",
      " |      of list of filenames.\n",
      " |  \n",
      " |  setKillJobs(self, killJobs)\n",
      " |      Kill previously submitted runs.\n",
      " |      killJobs can be given as a single integer id or list\n",
      " |      of integer ids.\n",
      " |  \n",
      " |  setLocal(self, local=True)\n",
      " |      Turn submit local execution on or off.\n",
      " |  \n",
      " |  setManager(self, manager)\n",
      " |      Set manager for submit run.\n",
      " |      By default manager is set by the venue or tool configuration.\n",
      " |  \n",
      " |  setNcores(self, nCores)\n",
      " |      Set number of cores requested for submit run.\n",
      " |      If only one core is required no setting is necessary.\n",
      " |  \n",
      " |  setPPN(self, ppn)\n",
      " |      Set number of cores per node requested for submit run.\n",
      " |      If number of cores per node is not set for the submit run\n",
      " |      a default number of cores per node is set based on the\n",
      " |      venue configuration.  This default value is typical based\n",
      " |      on the node hardware.\n",
      " |  \n",
      " |  setParameters(self, parameters, separator=None)\n",
      " |      Supply set of parameters for submit run.\n",
      " |      parameters can be specified as a single string or\n",
      " |      of list of strings.  Previously set parameters are\n",
      " |      removed.\n",
      " |  \n",
      " |  setProgress(self, detail=None)\n",
      " |      Specify progress reporting style.\n",
      " |      detail       submit arguments\n",
      " |      None \n",
      " |      curses       --progress curses  \n",
      " |      submit       --progress submit\n",
      " |      text         --progress text\n",
      " |      pegasus      --progress pegasus\n",
      " |      silent       --progress silent\n",
      " |  \n",
      " |  setQueryJobs(self, queryJobs)\n",
      " |      Do a query for the status of previously submitted runs.\n",
      " |      queryJobs can be given as a single integer id or list\n",
      " |      of integer ids.\n",
      " |  \n",
      " |  setQuota(self, quota)\n",
      " |      Enable or disable quota limit for submit run.\n",
      " |      If enabled your HUB disk quota is used to limit data\n",
      " |      generation on the remote resource.  This property is\n",
      " |      enabled by default.\n",
      " |  \n",
      " |  setRedundancy(self, redundancy)\n",
      " |      Set redundancy factor for submit run.\n",
      " |      The default redundancy factor is set by submit configuration.\n",
      " |  \n",
      " |  setReportMetrics(self, reportMetrics=True)\n",
      " |      Turn submit resource metrics reporting on or off.\n",
      " |  \n",
      " |  setRunName(self, runName)\n",
      " |      Set submit run name.\n",
      " |      Default run name is the auto generated submit jobId.\n",
      " |      The runName is used to set the standard output and\n",
      " |      standard error filenames.\n",
      " |  \n",
      " |  setStdin(self, stdinPath)\n",
      " |      Specify path to stdin file.\n",
      " |  \n",
      " |  setTailFiles(self, tailFiles)\n",
      " |      Enable real time reporting of files other than\n",
      " |      standard output and standard error.\n",
      " |      tailFiles can be specified as a single filename\n",
      " |      or a list of filenames.  To specify the number (#)\n",
      " |      of lines to report add :# to the filename.\n",
      " |  \n",
      " |  setTailStderr(self, tailStderr=True, tailStderrNlines=None)\n",
      " |      Enable or disable real time reporting of standard error file.\n",
      " |  \n",
      " |  setTailStdout(self, tailStdout=True, tailStdoutNlines=None)\n",
      " |      Enable or disable real time reporting of standard output file.\n",
      " |  \n",
      " |  setVenue(self, venue)\n",
      " |      Request that run be submitted to \"venue\".\n",
      " |  \n",
      " |  setVenueStatus(self, venueStatus)\n",
      " |      Request status of submit venue named venueStatus.\n",
      " |  \n",
      " |  setVersion(self, detail=None)\n",
      " |      Request complete or partial version information.\n",
      " |      detail       submit arguments\n",
      " |      None         --version\n",
      " |      client       --version client\n",
      " |      server       --version server\n",
      " |      distributor  --version distributor\n",
      " |  \n",
      " |  setWait(self, wait=True)\n",
      " |      Wait for period of reduced run submission rate to submit run.\n",
      " |      Users have a limited rate at which they are allowed to submit jobs.\n",
      " |      The measured rate of run submission is measured over time with\n",
      " |      more attention payed to the most recent submission.\n",
      " |  \n",
      " |  setWallTime(self, wallTime)\n",
      " |      Set the wall time limit for batch queue runs.\n",
      " |      wallTime can be given as integer or floating\n",
      " |      point number of minutes.\n",
      " |  \n",
      " |  show(self, args=None, textWidth=80)\n",
      " |      Show submit command as determined from previous settings.\n",
      " |      If args is supplied previous settings are ignored but not\n",
      " |      replaced or overwritten.\n",
      " |  \n",
      " |  submit(self, args=None, stdin=None)\n",
      " |      Execute submit command as determined from previous settings.\n",
      " |      If args is supplied previous settings are ignored but not\n",
      " |      replaced or overwritten.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  CONFIGURATIONDIRECTORY = '/etc/submit'\n",
      " |  \n",
      " |  CONFIGURATIONFILE = 'submit-client.conf'\n",
      " |  \n",
      " |  HUBLOGFILE = '.submit.log'\n",
      " |  \n",
      " |  HUBLOGPATH = '/tmp/submit/.submit.log'\n",
      " |  \n",
      " |  LOGDIRECTORY = '/tmp/submit'\n",
      " |  \n",
      " |  SEPARATORDEFAULT = ','\n",
      " |  \n",
      " |  TAILNLINESDEFAULT = 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from hubzero.submit.SubmitCommand import SubmitCommand\n",
    "\n",
    "submitCommand = SubmitCommand()\n",
    "help (submitCommand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Help about the underlying **submit** command can be easily reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: submit [options]\n",
      "\n",
      "Options:\n",
      "  -h, --help            Report command usage. Optionally request listing of\n",
      "                        managers, tools, venues, or examples.\n",
      "  -l, --local           Execute command locally\n",
      "  --status              Report status for runs executing remotely.\n",
      "  -k, --kill            Kill runs executing remotely.\n",
      "  --venueStatus         Report venue status.\n",
      "  -v, --venue           Remote job destination\n",
      "  -i, --inputfile       Input file\n",
      "  -p, --parameters      Parameter sweep variables. See examples.\n",
      "  -d, --data            Parametric variable data - csv format\n",
      "  -s SEPARATOR, --separator=SEPARATOR\n",
      "                        Parameter sweep variable list separator\n",
      "  -n NCPUS, --nCpus=NCPUS\n",
      "                        Number of processors for MPI execution\n",
      "  -N PPN, --ppn=PPN     Number of processors/node for MPI execution\n",
      "  -w WALLTIME, --wallTime=WALLTIME\n",
      "                        Estimated walltime hh:mm:ss or minutes\n",
      "  -e, --env             Variable=value\n",
      "  --runName=RUNNAME     Name used for directories and files created during the\n",
      "                        run. Restricted to alphanumeric characters\n",
      "  -m, --manager         Multiprocessor job manager\n",
      "  -r NREDUNDANT, --redundancy=NREDUNDANT\n",
      "                        Number of indentical simulations to execute in\n",
      "                        parallel\n",
      "  -M, --metrics         Report resource usage on exit\n",
      "  --detach              Detach client after launching run\n",
      "  --attach=ATTACHID     Attach to previously detached started server\n",
      "  -W, --wait            Wait for reduced job load before submission\n",
      "  -Q, --quota           Enforce local user quota on remote execution host\n",
      "  -q, --noquota         Do not enforce local user quota on remote execution\n",
      "                        host\n",
      "  --tailStdout          Periodically report tail of stdout file.\n",
      "  --tailStderr          Periodically report tail of stderr file.\n",
      "  --tail                Periodically report tail of application file.\n",
      "  --progress            Show progress method. Choices are auto, curses,\n",
      "                        submit, text, pegasus, or silent.\n"
     ]
    }
   ],
   "source": [
    "submitCommand = SubmitCommand()\n",
    "result = submitCommand.submit(['--help'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A listing of available venues can be listed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Currently available VENUES are:\n",
      "   OSGFactory\n",
      "   RedCloud\n",
      "   compute@comet_nanobio\n",
      "   conte\n",
      "   datalimited@rice\n",
      "   ncn-hub@conte\n",
      "   ncn-hub@rice\n",
      "   ncn-hub_L@conte\n",
      "   ncn-hub_L@rice\n",
      "   ncn-hub_M@conte\n",
      "   ncn-hub_M@rice\n",
      "   ncn-hub_S@conte\n",
      "   ncn-hub_S@rice\n",
      "   ncn-hub_XL@conte\n",
      "   ncn-hub_XL@rice\n",
      "   ncn@conte\n",
      "   ncn@rice\n",
      "   ncn_L@conte\n",
      "   ncn_L@rice\n",
      "   ncn_M@conte\n",
      "   ncn_M@rice\n",
      "   ncn_S@conte\n",
      "   ncn_S@rice\n",
      "   ncn_XL@conte\n",
      "   ncn_XL@rice\n",
      "   partner@halsteadgpu\n",
      "   punch\n",
      "   rcac-ncn\n",
      "   rcac-ncn-hub\n",
      "   rcac-standby\n",
      "   rcac_L\n",
      "   rcac_M\n",
      "   rcac_S\n",
      "   rcac_XL\n",
      "   rice\n",
      "   shared@comet_nanobio\n",
      "   standby@conte\n",
      "   standby@rice\n",
      "   standby_L@conte\n",
      "   standby_L@rice\n",
      "   standby_M@conte\n",
      "   standby_M@rice\n",
      "   standby_S@conte\n",
      "   standby_S@rice\n",
      "   standby_XL@conte\n",
      "   standby_XL@rice\n",
      "   submithost\n"
     ]
    }
   ],
   "source": [
    "submitCommand = SubmitCommand()\n",
    "submitCommand.setHelp(detail='venues')\n",
    "result = submitCommand.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A listing of available staged tools can be listed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Currently available TOOLs are:\n",
      "   1dchainmd_r15\n",
      "   1dfdmht_r28\n",
      "   CAC-runapp\n",
      "   abase_r9\n",
      "   abinit-6.12.3\n",
      "   abinit-7.10.4\n",
      "   acmenpds-r49\n",
      "   adept_r32\n",
      "   adeptnpt_r151\n",
      "   advte_r15\n",
      "   ahpull_r27\n",
      "   amobt_r51\n",
      "   angel_r50\n",
      "   annihilate_r28\n",
      "   arbd-r15\n",
      "   arbd-r3\n",
      "   archimedes_r71\n",
      "   asts_r8\n",
      "   berkeleygw-1178_sigma\n",
      "   berkeleygw-1178_xi0\n",
      "   biconvex-r15\n",
      "   binbrush_r15\n",
      "   biolab_r64\n",
      "   biomoca_r29\n",
      "   biophotonicsim-r7\n",
      "   bmcsuite_r44\n",
      "   bowtie_r165\n",
      "   bsclab_r32\n",
      "   btesolver_r41\n",
      "   bulkmc_r39\n",
      "   bulkmobility_r13\n",
      "   cadnanovis_r41\n",
      "   carrierconc_r12\n",
      "   ccamt_r12\n",
      "   cdlev_r10\n",
      "   circuitelements_r4\n",
      "   cndo_r38\n",
      "   cnia_r20\n",
      "   cnia_r24\n",
      "   cntbands-ext_r41\n",
      "   cntbte_r25\n",
      "   cntmob_r44\n",
      "   cntnemscant_r7\n",
      "   cntnemsff_r7\n",
      "   cntphonons_r25\n",
      "   cntrelay_r25\n",
      "   complam_r35\n",
      "   cond3d_r14\n",
      "   contactmaps_r46\n",
      "   coulombsim_r20\n",
      "   crystal_viewer_r398\n",
      "   cvgraph_r26\n",
      "   dbrlaser_r5\n",
      "   ddaconvert_r69-pip\n",
      "   ddscat-7.3.0-intel-14_mpi\n",
      "   ddscat-7.3.0-intel-14_openmp\n",
      "   ddscat-7.3.0-intel-14_serial\n",
      "   ddsolarcell_r16\n",
      "   demons_r20\n",
      "   devrel_r33\n",
      "   diffanalyzer_r26\n",
      "   diffusionfcc_r8\n",
      "   diffusionhcp_r9\n",
      "   dpowj_r19\n",
      "   dsers_r8\n",
      "   dsmc1d_r5\n",
      "   electromat_r44\n",
      "   espresso-4.1.1_average\n",
      "   espresso-4.1.1_band_plot\n",
      "   espresso-4.1.1_bands\n",
      "   espresso-4.1.1_bands_FS\n",
      "   espresso-4.1.1_cp\n",
      "   espresso-4.1.1_cppp\n",
      "   espresso-4.1.1_d3\n",
      "   espresso-4.1.1_dipole\n",
      "   espresso-4.1.1_dist\n",
      "   espresso-4.1.1_dos\n",
      "   espresso-4.1.1_dynmat\n",
      "   espresso-4.1.1_epsilon\n",
      "   espresso-4.1.1_ev\n",
      "   espresso-4.1.1_fqha\n",
      "   espresso-4.1.1_initial_state\n",
      "   espresso-4.1.1_iotk\n",
      "   espresso-4.1.1_iotk_print_kinds\n",
      "   espresso-4.1.1_kpoints\n",
      "   espresso-4.1.1_kvecs_FS\n",
      "   espresso-4.1.1_ld1\n",
      "   espresso-4.1.1_matdyn\n",
      "   espresso-4.1.1_metadyn_pp\n",
      "   espresso-4.1.1_path_int\n",
      "   espresso-4.1.1_ph\n",
      "   espresso-4.1.1_phcg\n",
      "   espresso-4.1.1_plan_avg\n",
      "   espresso-4.1.1_plotband\n",
      "   espresso-4.1.1_plotproj\n",
      "   espresso-4.1.1_plotrho\n",
      "   espresso-4.1.1_pmw\n",
      "   espresso-4.1.1_pp\n",
      "   espresso-4.1.1_projwfc\n",
      "   espresso-4.1.1_pw\n",
      "   espresso-4.1.1_pw2casino\n",
      "   espresso-4.1.1_pw2gw\n",
      "   espresso-4.1.1_pw2wannier90\n",
      "   espresso-4.1.1_pw_export\n",
      "   espresso-4.1.1_pwcond\n",
      "   espresso-4.1.1_pwi2xsf\n",
      "   espresso-4.1.1_q2r\n",
      "   espresso-4.1.1_sumpdos\n",
      "   espresso-4.1.1_vdw\n",
      "   espresso-4.1.1_voronoy\n",
      "   espresso-4.1.1_wannier_ham\n",
      "   espresso-4.1.1_wannier_plot\n",
      "   espresso-4.1.1_wfdd\n",
      "   espresso-4.2_average\n",
      "   espresso-4.2_band_plot\n",
      "   espresso-4.2_bands\n",
      "   espresso-4.2_bands_FS\n",
      "   espresso-4.2_cp\n",
      "   espresso-4.2_cppp\n",
      "   espresso-4.2_d3\n",
      "   espresso-4.2_dist\n",
      "   espresso-4.2_dos\n",
      "   espresso-4.2_dynmat\n",
      "   espresso-4.2_epsilon\n",
      "   espresso-4.2_ev\n",
      "   espresso-4.2_gww\n",
      "   espresso-4.2_gww_fit\n",
      "   espresso-4.2_head\n",
      "   espresso-4.2_initial_state\n",
      "   espresso-4.2_iotk\n",
      "   espresso-4.2_iotk_print_kinds\n",
      "   espresso-4.2_kpoints\n",
      "   espresso-4.2_kvecs_FS\n",
      "   espresso-4.2_lambda\n",
      "   espresso-4.2_ld1\n",
      "   espresso-4.2_matdyn\n",
      "   espresso-4.2_path_int\n",
      "   espresso-4.2_ph\n",
      "   espresso-4.2_phcg\n",
      "   espresso-4.2_plan_avg\n",
      "   espresso-4.2_plotband\n",
      "   espresso-4.2_plotproj\n",
      "   espresso-4.2_plotrho\n",
      "   espresso-4.2_pmw\n",
      "   espresso-4.2_pp\n",
      "   espresso-4.2_projwfc\n",
      "   espresso-4.2_pw\n",
      "   espresso-4.2_pw2bgw\n",
      "   espresso-4.2_pw2casino\n",
      "   espresso-4.2_pw2gw\n",
      "   espresso-4.2_pw2wannier90\n",
      "   espresso-4.2_pw4gww\n",
      "   espresso-4.2_pw_export\n",
      "   espresso-4.2_pwcond\n",
      "   espresso-4.2_pwi2xsf\n",
      "   espresso-4.2_q2r\n",
      "   espresso-4.2_sumpdos\n",
      "   espresso-4.2_vdw\n",
      "   espresso-4.2_wannier_ham\n",
      "   espresso-4.2_wannier_plot\n",
      "   espresso-4.2_wfdd\n",
      "   espresso-4.3-xas_average\n",
      "   espresso-4.3-xas_bands\n",
      "   espresso-4.3-xas_bandstruct\n",
      "   espresso-4.3-xas_dos\n",
      "   espresso-4.3-xas_efermi\n",
      "   espresso-4.3-xas_epsilon\n",
      "   espresso-4.3-xas_generate_vdW_kernel_table\n",
      "   espresso-4.3-xas_initial_state\n",
      "   espresso-4.3-xas_iotk\n",
      "   espresso-4.3-xas_iotk_print_kinds\n",
      "   espresso-4.3-xas_plan_avg\n",
      "   espresso-4.3-xas_plotband\n",
      "   espresso-4.3-xas_plotproj\n",
      "   espresso-4.3-xas_plotrho\n",
      "   espresso-4.3-xas_pmw\n",
      "   espresso-4.3-xas_pp\n",
      "   espresso-4.3-xas_projwfc\n",
      "   espresso-4.3-xas_pw\n",
      "   espresso-4.3-xas_pw2gw\n",
      "   espresso-4.3-xas_pw2wannier90\n",
      "   espresso-4.3-xas_pw_export\n",
      "   espresso-4.3-xas_shirley_basis\n",
      "   espresso-4.3-xas_shirley_ham\n",
      "   espresso-4.3-xas_shirley_qdiagp\n",
      "   espresso-4.3-xas_shirley_xas\n",
      "   espresso-4.3-xas_sumpdos\n",
      "   espresso-4.3-xas_wannier_ham\n",
      "   espresso-4.3-xas_wannier_plot\n",
      "   espresso-4.3-xas_wfdd\n",
      "   espresso-4.3-xas_xas_para\n",
      "   espresso-5.1.2_average\n",
      "   espresso-5.1.2_band_plot\n",
      "   espresso-5.1.2_bands\n",
      "   espresso-5.1.2_bands_FS\n",
      "   espresso-5.1.2_bgw2pw\n",
      "   espresso-5.1.2_cp\n",
      "   espresso-5.1.2_cppp\n",
      "   espresso-5.1.2_d3\n",
      "   espresso-5.1.2_dist\n",
      "   espresso-5.1.2_dos\n",
      "   espresso-5.1.2_dynmat\n",
      "   espresso-5.1.2_epsilon\n",
      "   espresso-5.1.2_ev\n",
      "   espresso-5.1.2_fd\n",
      "   espresso-5.1.2_fd_ef\n",
      "   espresso-5.1.2_fd_ifc\n",
      "   espresso-5.1.2_fqha\n",
      "   espresso-5.1.2_generate_rVV10_kernel_table\n",
      "   espresso-5.1.2_generate_vdW_kernel_table\n",
      "   espresso-5.1.2_initial_state\n",
      "   espresso-5.1.2_iotk\n",
      "   espresso-5.1.2_iotk_print_kinds\n",
      "   espresso-5.1.2_kpoints\n",
      "   espresso-5.1.2_kvecs_FS\n",
      "   espresso-5.1.2_lambda\n",
      "   espresso-5.1.2_ld1\n",
      "   espresso-5.1.2_manypw\n",
      "   espresso-5.1.2_matdyn\n",
      "   espresso-5.1.2_molecularpdos\n",
      "   espresso-5.1.2_neb\n",
      "   espresso-5.1.2_path_interpolation\n",
      "   espresso-5.1.2_ph\n",
      "   espresso-5.1.2_phcg\n",
      "   espresso-5.1.2_plan_avg\n",
      "   espresso-5.1.2_plotband\n",
      "   espresso-5.1.2_plotproj\n",
      "   espresso-5.1.2_plotrho\n",
      "   espresso-5.1.2_pmw\n",
      "   espresso-5.1.2_pp\n",
      "   espresso-5.1.2_projwfc\n",
      "   espresso-5.1.2_pw\n",
      "   espresso-5.1.2_pw2bgw\n",
      "   espresso-5.1.2_pw2gw\n",
      "   espresso-5.1.2_pw2wannier90\n",
      "   espresso-5.1.2_pw_export\n",
      "   espresso-5.1.2_pwcond\n",
      "   espresso-5.1.2_pwi2xsf\n",
      "   espresso-5.1.2_q2qstar\n",
      "   espresso-5.1.2_q2r\n",
      "   espresso-5.1.2_q2trans\n",
      "   espresso-5.1.2_q2trans_fd\n",
      "   espresso-5.1.2_sumpdos\n",
      "   espresso-5.1.2_turbo_davidson\n",
      "   espresso-5.1.2_turbo_lanczos\n",
      "   espresso-5.1.2_turbo_spectrum\n",
      "   espresso-5.1.2_wannier_ham\n",
      "   espresso-5.1.2_wannier_plot\n",
      "   espresso-5.1.2_wfck2r\n",
      "   espresso-5.1.2_wfdd\n",
      "   espresso-5.1.2_xspectra\n",
      "   espresso-6.1_average\n",
      "   espresso-6.1_bands\n",
      "   espresso-6.1_bgw2pw\n",
      "   espresso-6.1_bse_main\n",
      "   espresso-6.1_cp\n",
      "   espresso-6.1_cppp\n",
      "   espresso-6.1_dist\n",
      "   espresso-6.1_dos\n",
      "   espresso-6.1_dynmat\n",
      "   espresso-6.1_epsilon\n",
      "   espresso-6.1_ev\n",
      "   espresso-6.1_fd\n",
      "   espresso-6.1_fd_ef\n",
      "   espresso-6.1_fd_ifc\n",
      "   espresso-6.1_fqha\n",
      "   espresso-6.1_fs\n",
      "   espresso-6.1_generate_rVV10_kernel_table\n",
      "   espresso-6.1_generate_vdW_kernel_table\n",
      "   espresso-6.1_gww\n",
      "   espresso-6.1_gww_fit\n",
      "   espresso-6.1_head\n",
      "   espresso-6.1_importexport_binary\n",
      "   espresso-6.1_initial_state\n",
      "   espresso-6.1_iotk\n",
      "   espresso-6.1_iotk_print_kinds\n",
      "   espresso-6.1_kpoints\n",
      "   espresso-6.1_lambda\n",
      "   espresso-6.1_ld1\n",
      "   espresso-6.1_manycp\n",
      "   espresso-6.1_manypw\n",
      "   espresso-6.1_matdyn\n",
      "   espresso-6.1_molecularnexafs\n",
      "   espresso-6.1_molecularpdos\n",
      "   espresso-6.1_neb\n",
      "   espresso-6.1_path_interpolation\n",
      "   espresso-6.1_ph\n",
      "   espresso-6.1_phcg\n",
      "   espresso-6.1_plan_avg\n",
      "   espresso-6.1_plotband\n",
      "   espresso-6.1_plotproj\n",
      "   espresso-6.1_plotrho\n",
      "   espresso-6.1_pmw\n",
      "   espresso-6.1_pp\n",
      "   espresso-6.1_projwfc\n",
      "   espresso-6.1_pw\n",
      "   espresso-6.1_pw2bgw\n",
      "   espresso-6.1_pw2gw\n",
      "   espresso-6.1_pw2wannier90\n",
      "   espresso-6.1_pw4gww\n",
      "   espresso-6.1_pw_export\n",
      "   espresso-6.1_pwcond\n",
      "   espresso-6.1_pwi2xsf\n",
      "   espresso-6.1_q2qstar\n",
      "   espresso-6.1_q2r\n",
      "   espresso-6.1_q2trans\n",
      "   espresso-6.1_q2trans_fd\n",
      "   espresso-6.1_spectra_correction\n",
      "   espresso-6.1_sumpdos\n",
      "   espresso-6.1_turbo_davidson\n",
      "   espresso-6.1_turbo_eels\n",
      "   espresso-6.1_turbo_lanczos\n",
      "   espresso-6.1_turbo_spectrum\n",
      "   espresso-6.1_wannier_ham\n",
      "   espresso-6.1_wannier_plot\n",
      "   espresso-6.1_wfck2r\n",
      "   espresso-6.1_wfdd\n",
      "   espresso-6.1_xspectra\n",
      "   espresso-6.2.1_alpha2f\n",
      "   espresso-6.2.1_average\n",
      "   espresso-6.2.1_bands\n",
      "   espresso-6.2.1_bgw2pw\n",
      "   espresso-6.2.1_bse_main\n",
      "   espresso-6.2.1_cell2ibrav\n",
      "   espresso-6.2.1_cp\n",
      "   espresso-6.2.1_cppp\n",
      "   espresso-6.2.1_dist\n",
      "   espresso-6.2.1_dos\n",
      "   espresso-6.2.1_dynmat\n",
      "   espresso-6.2.1_epsilon\n",
      "   espresso-6.2.1_ev\n",
      "   espresso-6.2.1_fd\n",
      "   espresso-6.2.1_fd_ef\n",
      "   espresso-6.2.1_fd_ifc\n",
      "   espresso-6.2.1_fermi_proj\n",
      "   espresso-6.2.1_fermi_velocity\n",
      "   espresso-6.2.1_fqha\n",
      "   espresso-6.2.1_fs\n",
      "   espresso-6.2.1_generate_rVV10_kernel_table\n",
      "   espresso-6.2.1_generate_vdW_kernel_table\n",
      "   espresso-6.2.1_gww\n",
      "   espresso-6.2.1_gww_fit\n",
      "   espresso-6.2.1_head\n",
      "   espresso-6.2.1_ibrav2cell\n",
      "   espresso-6.2.1_importexport_binary\n",
      "   espresso-6.2.1_initial_state\n",
      "   espresso-6.2.1_iotk\n",
      "   espresso-6.2.1_iotk_print_kinds\n",
      "   espresso-6.2.1_kpoints\n",
      "   espresso-6.2.1_lambda\n",
      "   espresso-6.2.1_ld1\n",
      "   espresso-6.2.1_manycp\n",
      "   espresso-6.2.1_manypw\n",
      "   espresso-6.2.1_matdyn\n",
      "   espresso-6.2.1_molecularnexafs\n",
      "   espresso-6.2.1_molecularpdos\n",
      "   espresso-6.2.1_neb\n",
      "   espresso-6.2.1_path_interpolation\n",
      "   espresso-6.2.1_ph\n",
      "   espresso-6.2.1_phcg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   espresso-6.2.1_plan_avg\n",
      "   espresso-6.2.1_plotband\n",
      "   espresso-6.2.1_plotproj\n",
      "   espresso-6.2.1_plotrho\n",
      "   espresso-6.2.1_pmw\n",
      "   espresso-6.2.1_pp\n",
      "   espresso-6.2.1_projwfc\n",
      "   espresso-6.2.1_pw\n",
      "   espresso-6.2.1_pw2bgw\n",
      "   espresso-6.2.1_pw2gw\n",
      "   espresso-6.2.1_pw2wannier90\n",
      "   espresso-6.2.1_pw4gww\n",
      "   espresso-6.2.1_pw_export\n",
      "   espresso-6.2.1_pwcond\n",
      "   espresso-6.2.1_pwi2xsf\n",
      "   espresso-6.2.1_q2qstar\n",
      "   espresso-6.2.1_q2r\n",
      "   espresso-6.2.1_q2trans\n",
      "   espresso-6.2.1_q2trans_fd\n",
      "   espresso-6.2.1_spectra_correction\n",
      "   espresso-6.2.1_sumpdos\n",
      "   espresso-6.2.1_turbo_davidson\n",
      "   espresso-6.2.1_turbo_eels\n",
      "   espresso-6.2.1_turbo_lanczos\n",
      "   espresso-6.2.1_turbo_spectrum\n",
      "   espresso-6.2.1_wannier_ham\n",
      "   espresso-6.2.1_wannier_plot\n",
      "   espresso-6.2.1_wfck2r\n",
      "   espresso-6.2.1_wfdd\n",
      "   espresso-6.2.1_xspectra\n",
      "   exdynamics_r93\n",
      "   fbsdcme_r33\n",
      "   fdical_r24\n",
      "   fdiscovery_r17\n",
      "   fermi_r83\n",
      "   fettoy_r41\n",
      "   ffettool_r18\n",
      "   freeedge_r46\n",
      "   gamess-20130501\n",
      "   gamess-20170420\n",
      "   geneticalgo_r12\n",
      "   gfettool_r71\n",
      "   gnor_r5\n",
      "   gnrinterconnect_r10\n",
      "   gnrinterconnect_r12\n",
      "   gpu_heom_kernel_r33\n",
      "   gpu_heom_kernel_r35\n",
      "   greensolver-r17013\n",
      "   greentherm_r37\n",
      "   gromacs-4.0.5-mdrun\n",
      "   gromacs-4.5.4-mdrun\n",
      "   gromacs-5.0.4-mdrun\n",
      "   gromacs-5.0.7-mdrun\n",
      "   gscompaction_r97\n",
      "   habituationgwr_r11\n",
      "   hcius_r5\n",
      "   hotspice_r23\n",
      "   hyperrebo-r21\n",
      "   hypiesolver_r49\n",
      "   imod_r19\n",
      "   impadder_r6\n",
      "   jamming_r8\n",
      "   kpnanofet_r25\n",
      "   kronig_penney_r55\n",
      "   lammps-01Feb14-parallel\n",
      "   lammps-06Apr15-parallel\n",
      "   lammps-06Apr15-serial\n",
      "   lammps-07Jul09-serial\n",
      "   lammps-09Dec14-parallel\n",
      "   lammps-10Aug15-parallel\n",
      "   lammps-10Aug15-serial\n",
      "   lammps-10Aug15_EChemDID-parallel\n",
      "   lammps-10Aug15_EChemDID-serial\n",
      "   lammps-15Jan10-serial\n",
      "   lammps-15May15-parallel\n",
      "   lammps-15May15-serial\n",
      "   lammps-17Feb12-parallel\n",
      "   lammps-17Feb12-serial\n",
      "   lammps-31Mar17-parallel\n",
      "   lammps-31Mar17-serial\n",
      "   lammps-4Jul12-parallel\n",
      "   lantrap_r11\n",
      "   lcao_v2.58b_RCAC_parallel\n",
      "   lcao_v2.58b_RCAC_serial\n",
      "   lcao_v2.65c_RCAC_parallel\n",
      "   lcao_v2.65c_RCAC_serial\n",
      "   lcoe_r9\n",
      "   lfmobility_r20\n",
      "   libefp-1.4.2_efpmd\n",
      "   lorentzfit_r14\n",
      "   mail2self\n",
      "   matdcal_r15\n",
      "   matrix2surface_r10\n",
      "   mcde_r14\n",
      "   mcdna_r11\n",
      "   mctrigate_r24\n",
      "   medici\n",
      "   meep-1.1.1-mpi\n",
      "   meep-1.2-mpi\n",
      "   meep-1.2.1-mpi\n",
      "   memristor_r29\n",
      "   mgbasic_r8\n",
      "   mgnanowirefet_r71\n",
      "   micellemd_r30\n",
      "   mif_r6\n",
      "   minimol_r177\n",
      "   mmst_r26\n",
      "   mmsttf_r41\n",
      "   mobiresis_r8\n",
      "   moca-ensemble_r12\n",
      "   moca_r39\n",
      "   molctoy_r11\n",
      "   molexpl_r22\n",
      "   molst_r20\n",
      "   moose-a2439c3_combined-opt\n",
      "   moose-c03\n",
      "   moscntr_r27\n",
      "   mosctool_r13\n",
      "   mosfetsat_r66\n",
      "   mpb_r16\n",
      "   msugmmpc_r4\n",
      "   mtjlab_r40\n",
      "   nacresimulator_r35\n",
      "   namd2-2.9\n",
      "   nanobiophotsim-r9\n",
      "   nanocmos_r24\n",
      "   nanoconfinement-r21\n",
      "   nanoconfinement-r27\n",
      "   nanogromacs_r40\n",
      "   nanogromacsdemo_r28\n",
      "   nanoin_r5\n",
      "   nanoindentation_r45\n",
      "   nanomos-r240\n",
      "   nanonet_r94\n",
      "   nanoplasticity_r67\n",
      "   nanoplasticity_r71\n",
      "   nanossl_r54\n",
      "   nbrush_r29\n",
      "   nccpf_r25\n",
      "   nemo-r17350\n",
      "   nemo-r17881\n",
      "   nemo-r19861\n",
      "   nemo-r21064\n",
      "   nemo-r21229\n",
      "   nemo-r21263\n",
      "   nemo-r21335\n",
      "   nemo-r21797\n",
      "   nemo-r22555\n",
      "   nmie_r18\n",
      "   nplongbasedda_r16\n",
      "   npshortbasedda_r12\n",
      "   nrr_r75_matchSeries\n",
      "   nsoptics_r34\n",
      "   nwabsorption_r14\n",
      "   ohmslaw_r10\n",
      "   omen-r17013\n",
      "   omenwire-r17551\n",
      "   opt_r17\n",
      "   opticslab-r9\n",
      "   optodet_r52\n",
      "   opv_r9\n",
      "   orcatool_r29\n",
      "   pc4nanobio-r46\n",
      "   pcpbt_r99\n",
      "   pegasus-plan\n",
      "   perfectabsorber_r40\n",
      "   periodicpot_r21\n",
      "   pertdd_r10\n",
      "   pete_r50\n",
      "   phcband_r11\n",
      "   phononlifetime_r103\n",
      "   phononlifetime_r57\n",
      "   photonicsdb_r174\n",
      "   piezoharvest_r38\n",
      "   pimc_r19\n",
      "   pnlongbasedda_r17\n",
      "   pnppeptide_r27\n",
      "   pnshortbasedda_r12\n",
      "   polymatic_r75\n",
      "   poreblazer-2.0.0_psd\n",
      "   predicts1d_r36\n",
      "   predicts2d_r18\n",
      "   prolabcdd_r12\n",
      "   prolabdcd_r12\n",
      "   prolabox_r18\n",
      "   prolaboxflux_r10\n",
      "   prophet_r27\n",
      "   pvanalyzer_r6\n",
      "   pvlimits_r12\n",
      "   pvpanelsim_r15\n",
      "   qcmethod_r17\n",
      "   qcrf4photo_r9\n",
      "   qdotled_r71\n",
      "   qpc_r17\n",
      "   quamc2d_r75\n",
      "   qudosim_r52\n",
      "   rcac-gromacs-4.0.7-mdrun\n",
      "   reaxff597a_r56\n",
      "   rebomd_r16\n",
      "   resistorcode_r14\n",
      "   rtd_r25\n",
      "   rtdnegf_r355\n",
      "   s4-1.0.0\n",
      "   s4sim_r36\n",
      "   sandp_r5\n",
      "   sbcnfet_r30\n",
      "   schred_r88\n",
      "   semidop_r16\n",
      "   siesta-2.0.1-parallel\n",
      "   siesta_r154\n",
      "   simsn-r231\n",
      "   smc_small_r19\n",
      "   smdc_r16\n",
      "   sparta-17Jun15-parallel\n",
      "   sparta-17Jun15-serial\n",
      "   sparta-21Aug15-parallel\n",
      "   sparta-21Aug15-serial\n",
      "   spectraesrabs_r17\n",
      "   spice3f4_r19\n",
      "   spincoupleddots_r11\n",
      "   spinprecession_r11\n",
      "   stick2d_r13\n",
      "   stickslip_r64\n",
      "   sugar_r47\n",
      "   sugaradxl_r20\n",
      "   sugarchevron_r24\n",
      "   sugarnl_r14\n",
      "   sugartangcd_r25\n",
      "   swntjiv_r27\n",
      "   tec_r6\n",
      "   tedev_r21\n",
      "   tedvis_r24\n",
      "   teg_r36\n",
      "   temlattice_r27\n",
      "   thermo_r61\n",
      "   tpxsim_r26\n",
      "   tsuprem4\n",
      "   ttmmd_r22\n",
      "   tunnelfet_r41\n",
      "   twounitintegrat_r16\n",
      "   uvspec_r20\n",
      "   velstoreleak_r12\n",
      "   vides_r65\n",
      "   viscoindent_r32\n",
      "   vkmlsd3d_r8\n",
      "   vsepr_r8\n",
      "   wilsoncpg_r10\n",
      "   xas-r214\n",
      "   xas-scf-r214\n",
      "   xpsts_r23\n",
      "   zeno_r28\n"
     ]
    }
   ],
   "source": [
    "submitCommand = SubmitCommand()\n",
    "submitCommand.setHelp(detail='tools')\n",
    "result = submitCommand.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes we can use a Python application that is part of the Pegasus Tutorial tool. Because it is installed in the /apps directory it is available for submisison to most venues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "applicationCode = '/apps/pegtut/current/examples/capacitor_voltage/sim1.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SubmitCommand class has a method that excepts command arguments as a simple list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 6614639 registered 1 job instance. Tue May  1 16:00:07 2018\n",
      "Run 6614639 instance 1 released for submission. Tue May  1 16:00:45 2018\n",
      "(945675.0) Job Submitted at OSGFactory Tue May  1 16:00:51 2018\n",
      "(945675.0) Job Done at OSGFactory Tue May  1 16:02:16 2018\n",
      "{'jobId': 6614639, 'runName': '06614639', 'exitCode': 0}\n"
     ]
    }
   ],
   "source": [
    "submitCommand = SubmitCommand()\n",
    "result = submitCommand.submit(['-w','5',applicationCode,'--C','0.001','--Vin','3'])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should notice that the single run resulted in submission of jobs to three different sites.  When no venue is specified and the application is not staged at any remote venues redundant jobs are submited.  When one job completes sucessfully the other jobs are terminated.\n",
    "The result dictionary has three members.  The *jobId* is the unique identifier given by **submit** to every run.  *runName* is the name of the run and by default it matches the *jobId*.  *runName* can be optionally set with **submit** arguments.  Standard output and standard error files generated by remote application execution are returned as *runName*.stdout and *runName*.stderr.  The standard error file will not be returned if it is empty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./sim1.py --C 0.001 --Vin 3\r\n"
     ]
    }
   ],
   "source": [
    "runStdout = result['runName'] + '.stdout'\n",
    "!cat $runStdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: 06614639.stderr: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "runStderr = result['runName'] + '.stderr'\n",
    "!cat $runStderr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the set methods and specifying a particular venue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit --venue OSGFactory --wallTime 5\n",
      "       /apps/pegtut/current/examples/capacitor_voltage/sim1.py --C 0.001 --Vin 3\n",
      "Run 6614643 registered 1 job instance. Tue May  1 16:02:23 2018\n",
      "Run 6614643 instance 1 released for submission. Tue May  1 16:02:43 2018\n",
      "(945676.0) Job Submitted at OSGFactory Tue May  1 16:02:50 2018\n",
      "(945676.0) Job Done at OSGFactory Tue May  1 16:03:58 2018\n"
     ]
    }
   ],
   "source": [
    "submitCommand = SubmitCommand()\n",
    "submitCommand.setWallTime(5)\n",
    "submitCommand.setVenue('OSGFactory')\n",
    "submitCommand.setCommand(applicationCode)\n",
    "submitCommand.setCommandArguments(['--C','0.001','--Vin','3'])\n",
    "submitCommand.show()\n",
    "result = submitCommand.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example with a parameter sweep over two variables.  Parameter sweep results are returned in a directory named *runName*.  Each job in the sweep has a separate subdirectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit --wallTime 5 --parameters @@Vin=1:2:10 --parameters @@C=100e-6,100e-5\n",
      "       /apps/pegtut/current/examples/capacitor_voltage/sim1.py --C @@C --Vin\n",
      "       @@Vin\n",
      "Run 6614647 registered 1 job instance. Tue May  1 16:04:31 2018\n",
      "Run 6614647 instance 0 released for submission. Tue May  1 16:04:44 2018\n",
      "(945677.0) DAG Submitted at WF-OSGFactory Tue May  1 16:05:00 2018\n",
      "(945677.0) DAG Running at WF-OSGFactory Tue May  1 16:05:08 2018\n",
      "(945677.0) DAG Done at WF-OSGFactory Tue May  1 16:06:57 2018\n",
      "Simulations complete. Results are stored in directory /home/nanohub/mmh/data/sessions/1301182/run_5Wz8uf/06614647\n",
      "06614647:\n",
      "01  05\t09\t\t\t   pegasusjobstats.csv\t    pegasussummary.csv\n",
      "02  06\t10\t\t\t   pegasusjobstats.txt\n",
      "03  07\tparameterCombinations.csv  pegasusstatus.txt\n",
      "04  08\tpegasus.analysis\t   pegasussummary-time.csv\n",
      "\n",
      "06614647/01:\n",
      "\n",
      "06614647/02:\n",
      "\n",
      "06614647/03:\n",
      "\n",
      "06614647/04:\n",
      "\n",
      "06614647/05:\n",
      "\n",
      "06614647/06:\n",
      "\n",
      "06614647/07:\n",
      "\n",
      "06614647/08:\n",
      "\n",
      "06614647/09:\n",
      "\n",
      "06614647/10:\n"
     ]
    }
   ],
   "source": [
    "submitCommand = SubmitCommand()\n",
    "submitCommand.setWallTime(5)\n",
    "submitCommand.setParameters(['@@Vin=1:2:10','@@C=100e-6,100e-5'])\n",
    "submitCommand.setCommand(applicationCode)\n",
    "submitCommand.setCommandArguments(['--C','@@C','--Vin','@@Vin'])\n",
    "submitCommand.show()\n",
    "result = submitCommand.submit()\n",
    "\n",
    "runResultsDir = result['runName']\n",
    "!ls -R $runResultsDir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative progress reporting methods are provided to facilitate advanced reporting. As an example the *submit* progress reporting method output is injested by Rappture and rendered as a progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit --wallTime 5 --parameters @@Vin=1:2:10 --parameters @@C=100e-6,100e-5\n",
      "       --progress submit /apps/pegtut/current/examples/capacitor_voltage/sim1.py\n",
      "       --C @@C --Vin @@Vin\n",
      "=SUBMIT-PROGRESS=> aborted=0 finished=0 failed=0 executing=0 waiting=10 setting_up=0 setup=0 %done=0.00 timestamp=1525205280.9\n",
      "=SUBMIT-PROGRESS=> aborted=0 finished=10 failed=0 executing=0 waiting=0 setting_up=0 setup=0 %done=100.00 timestamp=1525205396.5\n",
      "Simulations complete. Results are stored in directory /home/nanohub/mmh/data/sessions/1301182/run_LlRw5S/06614656\n"
     ]
    }
   ],
   "source": [
    "submitCommand = SubmitCommand()\n",
    "submitCommand.setWallTime(5)\n",
    "submitCommand.setParameters(['@@Vin=1:2:10','@@C=100e-6,100e-5'])\n",
    "submitCommand.setProgress(detail='submit')\n",
    "submitCommand.setCommand(applicationCode)\n",
    "submitCommand.setCommandArguments(['--C','@@C','--Vin','@@Vin'])\n",
    "submitCommand.show()\n",
    "result = submitCommand.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter sweep variable values can also be read from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@Vin,@@C\r\n",
      "1.000000,0.000100\r\n",
      "1.000000,0.001000\r\n",
      "2.000000,0.000100\r\n",
      "2.000000,0.001000\r\n",
      "3.000000,0.000100\r\n",
      "3.000000,0.001000\r\n",
      "4.000000,0.000100\r\n",
      "4.000000,0.001000\r\n",
      "5.000000,0.000100\r\n",
      "5.000000,0.001000\r\n"
     ]
    }
   ],
   "source": [
    "with open(\"input.csv\",'w') as fpInput:\n",
    "   fpInput.write(\"@@Vin,@@C\\n\")\n",
    "   for v in range(1,6):\n",
    "      for c in (0.0001,0.001):\n",
    "         fpInput.write(\"%f,%f\\n\" % (v,c))\n",
    "!cat input.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit --wallTime 5 --data input.csv\n",
      "       /apps/pegtut/current/examples/capacitor_voltage/sim1.py --C @@C --Vin\n",
      "       @@Vin\n",
      "Run 6614664 registered 1 job instance. Tue May  1 16:10:36 2018\n",
      "Run 6614664 instance 0 released for submission. Tue May  1 16:10:47 2018\n",
      "(945691.0) DAG Submitted at WF-OSGFactory-RHEL6 Tue May  1 16:10:59 2018\n",
      "(945691.0) DAG Running at WF-OSGFactory-RHEL6 Tue May  1 16:11:09 2018\n",
      "(945691.0) DAG Done at WF-OSGFactory-RHEL6 Tue May  1 16:12:56 2018\n",
      "Simulations complete. Results are stored in directory /home/nanohub/mmh/data/sessions/1301182/run_h4eIUI/06614664\n"
     ]
    }
   ],
   "source": [
    "submitCommand = SubmitCommand()\n",
    "submitCommand.setWallTime(5)\n",
    "submitCommand.setDataFile('input.csv')\n",
    "submitCommand.setCommand(applicationCode)\n",
    "submitCommand.setCommandArguments(['--C','@@C','--Vin','@@Vin'])\n",
    "submitCommand.show()\n",
    "result = submitCommand.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mapping of variable combinations to job number is contained in the parameterCombinations.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# command: /apps/pegtut/current/examples/capacitor_voltage/sim1.py --C @@C --Vin @@Vin\r",
      "\r\n",
      "# started: Tue May  1 16:10:51 EDT 2018\r",
      "\r\n",
      "# finished: Tue May  1 16:12:56 EDT 2018\r",
      "\r\n",
      "# completed: 10/10 jobs\r",
      "\r\n",
      "Id,Status,Vin,C\r",
      "\r\n",
      "01,finished,1.000000,0.000100\r",
      "\r\n",
      "02,finished,1.000000,0.001000\r",
      "\r\n",
      "03,finished,2.000000,0.000100\r",
      "\r\n",
      "04,finished,2.000000,0.001000\r",
      "\r\n",
      "05,finished,3.000000,0.000100\r",
      "\r\n",
      "06,finished,3.000000,0.001000\r",
      "\r\n",
      "07,finished,4.000000,0.000100\r",
      "\r\n",
      "08,finished,4.000000,0.001000\r",
      "\r\n",
      "09,finished,5.000000,0.000100\r",
      "\r\n",
      "10,finished,5.000000,0.001000\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "combinationsFile = os.path.join(result['runName'],'parameterCombinations.csv')\n",
    "!cat $combinationsFile"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
